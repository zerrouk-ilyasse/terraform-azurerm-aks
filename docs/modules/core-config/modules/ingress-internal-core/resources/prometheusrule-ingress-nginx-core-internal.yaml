# https://promcat.io/apps/nginx-ingress
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ingress-nginx-internal-core
  namespace: monitoring
  labels:
    lnrs.io/k8s-platform: "true"
    lnrs.io/monitoring-platform: "true"
    lnrs.io/prometheus-rule: "true"
spec:
  groups:
    - name: ingress-nginx-internal-core
      rules:
        - alert: NginxHighHttp4xxErrorRate
          expr: sum(rate(nginx_ingress_controller_requests{controller_class="k8s.io/nginx-internal-core",status=~"4.."}[1m])) / sum(rate(nginx_ingress_controller_requests{controller_class="k8s.io/nginx-internal-core"}[1m])) * 100 > 5
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Nginx high HTTP 4xx error rate (instance {{ $labels.instance }})
            description: "Too many HTTP requests with status 4xx (> 5%)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        - alert: NginxHighHttp5xxErrorRate
          expr: sum(rate(nginx_ingress_controller_requests{controller_class="k8s.io/nginx-internal-core",status=~"^5.."}[1m])) / sum(rate(nginx_ingress_controller_requests{controller_class="k8s.io/nginx-internal-core"}[1m])) * 100 > 5
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Nginx high HTTP 5xx error rate (instance {{ $labels.instance }})
            description: "Too many HTTP requests with status 5xx (> 5%)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        - alert: NginxLatencyHigh
          expr: histogram_quantile(0.99, sum(rate(nginx_ingress_controller_request_duration_seconds_bucket{controller_class="k8s.io/nginx-internal-core"}[30m])) by (host, node)) > 10
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: Nginx latency high (instance {{ $labels.instance }})
            description: "Nginx p99 latency is higher than 10 seconds\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
